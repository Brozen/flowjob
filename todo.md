## 功能

1. web/worker调tracker 从节点302到主节点 如心跳/web端创建任务等
2. tracker间如何维护worker的数据一致性 通过raft
3. 租户功能，租户是可开可不开 注册的时候通过ak/sk进行认证
6. bean方法任务作为特性，第一版不提供，第一版只做上传文件执行任务的方式以及通过string下发脚本
    文件下发目前考虑以下方式：
        tracker通过分布式文件系统等方式共享文件（由于tracker单节点，带宽）
        worker通过分布式文件系统等方式共享文件（worker在不同网络环境怎么处理）
        网络资源（worker端实现）
7. 日志靠约定，必须输出到标准输出流

### 路由策略

可以定义路由策略优先级？？？

1. 轮询 -> 加权轮询 默认各个节点的权重都为1
2. 随机
3. 一致性hash
4. 最不经常使用
5. 最近最久未使用
6. 指定节点提交
7. 基于worker标签下发：
    worker启动时候注册上来，admin端也可以手动增删
    include(a).include(b+d).exclude(c).exclude(d+e)

### 容错HA
容错
7. 故障转移
8. 忙碌转移  从预估的内存消耗、cpu消耗

### 任务提交方式
1. 定时
5. 接口

### 分片

作业分片

### 失败策略

Handler应该有个字段，判断是否能和其它的同时出发

1. LogJobErrorHandler 记录作业异常日志，但不中断作业执行
2. ThrowJobErrorHandler 抛出系统异常并中断作业执行
3. IgnoreJobErrorHandler 忽略系统异常且不中断作业执行
4. 自定义，如邮件、短信等

### 阻塞处理策略
调度过于密集执行器来不及处理时的处理策略；
1. 单机串行（默认）：调度请求进入单机执行器后，调度请求进入FIFO队列并以串行方式运行；
2. 丢弃后续调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，本次请求将会被丢弃并标记为失败；
3. 覆盖之前调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，将会终止运行中的调度任务并清空队列，然后运行本地调度任务；
故障策略：下发过程中worker发生故障（挂了），怎么处理
下发失败策略：下发给worker时，worker资源不足，怎么处理
执行失败策略：worker执行时，发生异常，怎么处理

### 处理模型
1. 单机 一个任务实例只会随机触发到一台Worker上，支持所有的任务类型
2. 广播 一个任务实例会广播到该分组所有Worker上执行，当所有Worker都执行完成，该任务才算完成。任意一台Worker执行失败，都算该任务失败。（比如一些定时清理磁盘等工作）
3. Map 基于MapJobProcessor，调用Map方法，即可实现大数据分布式跑批的能力???
4. MapReduce Map模型的扩展，新增Reduce接口，需要实现MapReduceJobProcessor???（MapReduce其实就比Map多了个Reduce操作，
在所有map任务执行后进行，Map和MapReduce和elasticjob以及xxl-job的分片我认为是一样的，就是将任务分为多份处理，不用DAG是因为这个任务划分的可能很多总不能人工处理）
广播-map-mapreduce都是下发所有，但是也能指定标签
使用sharding也能发挥MapReduce的作用

### 多语言执行
先不考虑，只支持客户端处理

### 语言支持
先考虑java clinet，尽量使用更少的代码逻辑实现client

### 权限
先不考虑

### 监控
先不考虑

### 前端
1. 工作日志输出
2. 任务治理

### 性能
1. 最低任务配置 下发任务前检查worker是否满足
2. 任务特别多的情况下 比如100万个店铺任务 理论来说应该集群，分开获取任务
加油提升


## 组件初期目标

### Tracker
1. worker信息注册
2. worker存活检测
3. 定时、延时任务检测（TimeWheel）与下发
4. 任务 增删查改
5. 任务 下发

### Worker
1. 启动注册
2. 上报or拉取 可用资源（CPU、Memory、Disk）
3. 上报or拉取 执行中的任务信息
4. 上报or拉取 任务执行
